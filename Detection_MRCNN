from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from mrcnn.utils import Dataset
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
from mrcnn.model import log
import re
import time
from mrcnn.model import data_generator
import datetime
import tensorflow as tf
import keras
import os
import scipy.io
import scipy.misc
import numpy as np
import pandas as pd
import PIL
import struct
import cv2
from numpy import expand_dims
from skimage.transform import resize
from keras import backend as K
from keras.layers import Input, Lambda, Conv2D, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D
from keras.models import load_model, Model
from keras.layers.merge import add, concatenate
from keras.preprocessing.image import load_img
from keras.preprocessing.image import img_to_array
from matplotlib import pyplot
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
from matplotlib.patches import Rectangle
import wandb
from wandb.keras import WandbCallback
from sklearn.model_selection import train_test_split


dataset_dir = '/data/Labrum'

images_dir = dataset_dir + '/images/'
annotations_dir = dataset_dir + '/annots/'
image_list = listdir(images_dir)
X_train, X_test = train_test_split(image_list, test_size=0.1, random_state=2021)
Xtrain, Xval = train_test_split(X_train, test_size=0.2, random_state=2021)
print(len(Xtrain))

# class that defines and loads the dataset
class DetectionDataset(Dataset):
    # load the dataset definitions
    def load_dataset(self, dataset_dir, is_train=True):
        # define one class
        self.add_class("dataset", 1, "Labrum")
        # find all images
        for filename in X_train:
            # extract image id
            image_id = filename[:-4]
            # skip all images after 150 if we are building the train set
            if is_train and filename in Xval:
                continue
            # skip all images before 150 if we are building the test/val set
            if not is_train and filename in Xtrain:
                continue
            img_path = images_dir + filename
            ann_path = annotations_dir + image_id + '.xml'
            # add to dataset
            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)
 
    def extract_boxes(self,filename):
        # load and parse the file
        tree = ElementTree.parse(filename)
        # get the root of the document
        root = tree.getroot()
        # extract each bounding box
        boxes = list()
        for box in root.findall('.//bndbox'):
            xmin = int(box.find('xmin').text)
            ymin = int(box.find('ymin').text)
            xmax = int(box.find('xmax').text)
            ymax = int(box.find('ymax').text)
            coors = [xmin, ymin, xmax, ymax]
            boxes.append(coors)
        # extract image dimensions
        width = int(root.find('.//size/width').text)
        height = int(root.find('.//size/height').text)
        return boxes, width, height
 
    # load the masks for an image
    def load_mask(self, image_id):
        # get details of image
        info = self.image_info[image_id]
        # define box file location
        path = info['annotation']
        # load XML
        boxes, w, h = self.extract_boxes(path)
        # create one array for all masks, each on a different channel
        masks = zeros([h, w, len(boxes)], dtype='uint8')
        # create masks
        class_ids = list()
        for i in range(len(boxes)):
            box = boxes[i]
            row_s, row_e = box[1], box[3]
            col_s, col_e = box[0], box[2]
            masks[row_s:row_e, col_s:col_e, i] = 1
            class_ids.append(self.class_names.index('Labrum'))
        return masks, asarray(class_ids, dtype='int32')
 
    # load an image reference
    def image_reference(self, image_id):
        info = self.image_info[image_id]
        return info['path']
 
 # train set
train_set = DetectionDataset()
train_set.load_dataset('Labrum', is_train=True)
train_set.prepare()
print('Train: %d' % len(train_set.image_ids))

test_set = DetectionDataset()
test_set.load_dataset('Labrum', is_train=False)
test_set.prepare()
print('Test: %d' % len(test_set.image_ids))

image_id = 0
image = train_set.load_image(image_id)
print(image.shape)
# load image mask
mask, class_ids = train_set.load_mask(image_id)
print(mask.shape)
# plot image
pyplot.imshow(image)
# plot mask
pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)
pyplot.show()

for i in range(9):
    # define subplot
    pyplot.subplot(330 + 1 + i)
    # plot raw pixel data
    image = train_set.load_image(i)
    pyplot.imshow(image)
    #plot all masks
    mask, _ = train_set.load_mask(i)
    for j in range(mask.shape[2]):
        pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)
# show the figure
pyplot.show()


sweep_config = {
   'method': 'grid',
   'parameters': {
       'RPN_ANCHOR_SCALES': {
           'values': [(8, 16, 32, 64, 128),
                     (4, 8, 16, 32, 64)]
       },
       'RPN_NMS_THRESHOLD':{
           'values':[0.7]
       }
       
   }
}
sweep_id = wandb.sweep(sweep_config, entity="wenxiaoyi", project="detection")

character_names = {0: 'Back Ground', 1: 'Labrum'}


class CustomCallback(keras.callbacks.Callback):
    def __init__(self, direc):
        """ Save params in constructor
        """
        self.direc = direc
    def on_epoch_end(self, epoch, logs=None):
        keys = list(logs.keys())
        
        self.model.save_weights(os.path.join(self.direc, "mask_rcnn_{epoch:02d}_object_detection.h5"))
        wandb.save(os.path.join(self.direc, "mask_rcnn_{epoch:02d}_object_detection.h5"))
        print("End epoch {} of training; got log keys: {}".format(epoch, keys))

class MaskRCNN(MaskRCNN):
    
    
    def set_log_dir(self, model_path=None):
        """Sets the model log directory and epoch counter.

        model_path: If None, or a format different from what this code uses
            then set a new log directory and start epochs from 0. Otherwise,
            extract the log directory and the epoch counter from the file
            name.
        """
        # Set date and epoch counter as if starting a new model
        self.epoch = 0
        now = datetime.datetime.now()

        # If we have a model path with date and epochs use them
        if model_path:
            # Continue from we left of. Get epoch and date from the file name
            # A sample model path might look like:
            # \path\to\logs\coco20171029T2315\mask_rcnn_coco_0001.h5 (Windows)
            # /path/to/logs/coco20171029T2315/mask_rcnn_coco_0001.h5 (Linux)
            regex = r".*[/\\][\w-]+(\d{4})(\d{2})(\d{2})T(\d{2})(\d{2})[/\\]mask\_rcnn\_[\w-]+(\d{4})\.h5"
            m = re.match(regex, model_path)
            if m:
                now = datetime.datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)),
                                        int(m.group(4)), int(m.group(5)))
                # Epoch number in file is 1-based, and in Keras code it's 0-based.
                # So, adjust for that then increment by one to start from the next epoch
                self.epoch = int(m.group(6)) - 1 + 1
                print('Re-starting from epoch %d' % self.epoch)

        # Directory for training logs
        self.log_dir = wandb.run.dir

        # Path to save after each epoch. Include placeholders that get filled by Keras.
        self.checkpoint_path = os.path.join(self.log_dir, "mask_rcnn_{}_*epoch*.h5".format(
            self.config.NAME.lower()))
        self.checkpoint_path = self.checkpoint_path.replace(
            "*epoch*", "{epoch:04d}")    
    
    
    
    
    
    def train(self, train_dataset, val_dataset, learning_rate, epochs, layers,
              augmentation=None, custom_callbacks=None, no_augmentation_sources=None):
        """Train the model.
        train_dataset, val_dataset: Training and validation Dataset objects.
        learning_rate: The learning rate to train with
        epochs: Number of training epochs. Note that previous training epochs
                are considered to be done alreay, so this actually determines
                the epochs to train in total rather than in this particaular
                call.
        layers: Allows selecting wich layers to train. It can be:
            - A regular expression to match layer names to train
            - One of these predefined values:
              heads: The RPN, classifier and mask heads of the network
              all: All the layers
              3+: Train Resnet stage 3 and up
              4+: Train Resnet stage 4 and up
              5+: Train Resnet stage 5 and up
        augmentation: Optional. An imgaug (https://github.com/aleju/imgaug)
            augmentation. For example, passing imgaug.augmenters.Fliplr(0.5)
            flips images right/left 50% of the time. You can pass complex
            augmentations as well. This augmentation applies 50% of the
            time, and when it does it flips images right/left half the time
            and adds a Gaussian blur with a random sigma in range 0 to 5.

                augmentation = imgaug.augmenters.Sometimes(0.5, [
                    imgaug.augmenters.Fliplr(0.5),
                    imgaug.augmenters.GaussianBlur(sigma=(0.0, 5.0))
                ])
        custom_callbacks: Optional. Add custom callbacks to be called
            with the keras fit_generator method. Must be list of type keras.callbacks.
        no_augmentation_sources: Optional. List of sources to exclude for
            augmentation. A source is string that identifies a dataset and is
            defined in the Dataset class.
        """
        assert self.mode == "training", "Create model in training mode."

        # Pre-defined layer regular expressions
        layer_regex = {
            # all layers but the backbone
            "heads": r"(mrcnn\_.*)|(rpn\_.*)|(fpn\_.*)",
            # From a specific Resnet stage and up
            "3+": r"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\_.*)|(rpn\_.*)|(fpn\_.*)",
            "4+": r"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\_.*)|(rpn\_.*)|(fpn\_.*)",
            "5+": r"(res5.*)|(bn5.*)|(mrcnn\_.*)|(rpn\_.*)|(fpn\_.*)",
            # All layers
            "all": ".*",
        }
        if layers in layer_regex.keys():
            layers = layer_regex[layers]

        # Data generators
        train_generator = data_generator(train_dataset, self.config, shuffle=True,
                                         augmentation=augmentation,
                                         batch_size=self.config.BATCH_SIZE)
        val_generator = data_generator(val_dataset, self.config, shuffle=True,
                                       batch_size=self.config.BATCH_SIZE)

        # Create log_dir if it does not exist
        if not os.path.exists(self.log_dir):
            os.makedirs(self.log_dir)
        filepath = os.path.join(self.log_dir, "/mask_rcnn_{epoch:02d}-{val_loss:.2f}.h5")
        # Callbacks
        callbacks = [
            keras.callbacks.TensorBoard(log_dir=self.log_dir,
                                        histogram_freq=0, write_graph=True, write_images=False),
#             WandbCallback(data_type="image", labels=CLASSES_TO_TAKE, save_weights_only=True),
#             CustomCallback(direc=self.log_dir)
#             keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True)
        ]

        # Add custom callbacks to the list
        if custom_callbacks:
            callbacks += custom_callbacks

        # Train
        log("\nStarting at epoch {}. LR={}\n".format(self.epoch, learning_rate))
        log("Checkpoint Path: {}".format(self.checkpoint_path))
        self.set_trainable(layers)
        self.compile(learning_rate, self.config.LEARNING_MOMENTUM)

        self.keras_model.fit_generator(
            train_generator,
            initial_epoch=self.epoch,
            epochs=epochs,
            steps_per_epoch=self.config.STEPS_PER_EPOCH,
            callbacks=callbacks,
            validation_data=val_generator,
            validation_steps=self.config.VALIDATION_STEPS,
            max_queue_size=100
        )
        self.epoch = max(self.epoch, epochs)


def train_sweep():
    # Specify the hyperparameter to be tuned along with
    # an initial value
    config_defaults = {
        'RPN_ANCHOR_SCALES': (8, 16, 32, 64, 128),
        'epochs': 20
    }
    wandb.init(config=config_defaults,sync_tensorboard =True)
    # Specify the other hyperparameters to the configuration
    config = wandb.config 
        
    class LabrumConfig(Config):
        """Configuration for training on the toy shapes dataset.
        Derives from the base Config class and overrides values specific
        to the toy shapes dataset.
        """
        # Give the configuration a recognizable name
        NAME = "Labrum_cfg"

        # Number of classes (including background)
        NUM_CLASSES = 1 + 1  # background + 2 types of cracks

        STEPS_PER_EPOCH = 500

    network_config = LabrumConfig()

    model = MaskRCNN(mode='training', model_dir='./', config=network_config)

    model.load_weights('/data/Labrum/mask_rcnn_COR_object_detection1.h5', by_name=True, exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])
    
    # filepath = os.path.join(wandb.run.dir, "/mask_rcnn_{epoch:02d}-{val_loss:.2f}.h5")
    
    custom_callbacks = [WandbCallback(data_type="image", labels=character_names, save_weights_only=True), 
    # keras.callbacks.ModelCheckpoint(os.path.join(wandb.run.dir, "mask_rcnn_{epoch:02d}_object_detection.h5"))
                        CustomCallback(direc=wandb.run.dir)
    # keras.callbacks.ModelCheckpoint(filepath)
                       ]
    model.train(train_set, test_set, 
                learning_rate=0.001, 
                epochs=config.epochs, 
                layers='heads', custom_callbacks = custom_callbacks)
